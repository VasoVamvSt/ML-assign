{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 2px solid black; padding: 10px;\">\n",
    "    <h1 style=\"margin-bottom: 3px;\">Machine Learning and business analytics</h1>\n",
    "    <h3 style=\"margin-top: 0px; color: gray;\">Sentiment analysis</h3>\n",
    "    <p>Date: September 2, 2024</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Group:** Team Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis - Part 2 - Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python 3.10.12\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- scikitlearn\n",
    "- langdetect/langid\n",
    "- nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import re\n",
    "import math\n",
    "import langid\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_path = f'../dataset/preprocessed/df_training_preprocessed.csv'\n",
    "test_file_path = f'../dataset/preprocessed/df_test_preprocessed.csv'\n",
    "\n",
    "TITLE_FONT_SIZE = 24\n",
    "LABEL_FONT_SIZE = 20\n",
    "AXIS_FONT_SIZE = 15\n",
    "FIGURE_MAX_WIDTH = 8\n",
    "FIGURE_MAX_HEIGHT = FIGURE_MAX_WIDTH*3/4\n",
    "\n",
    "CLEANR = re.compile('<.*?>') #remove html tags\n",
    "\n",
    "SPECIAL_CHARACTERS_REGEX = r'[-!@#$%^&*()_+={}\\[\\]:;\"\\'|<,>.?/~`]' # remove special character\n",
    "SYMBOLS_REGEX = re.compile(\"[\"\n",
    "                     u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                     u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "                     u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "                     u\"\\U0001F1E0-\\U0001F1FF\"  # Flags (iOS)\n",
    "                     u\"\\U00002500-\\U00002BEF\"  # Chinese/Japanese/Korean characters\n",
    "                     u\"\\U00002702-\\U000027B0\"\n",
    "                     u\"\\U00002702-\\U000027B0\"\n",
    "                     u\"\\U000024C2-\\U0001F251\"\n",
    "                     u\"\\U0001f926-\\U0001f937\"\n",
    "                     u\"\\U00010000-\\U0010ffff\"\n",
    "                     u\"\\u2640-\\u2642\"\n",
    "                     u\"\\u2600-\\u2B55\"\n",
    "                     u\"\\u200d\"\n",
    "                     u\"\\u23cf\"\n",
    "                     u\"\\u23e9\"\n",
    "                     u\"\\u231a\"\n",
    "                     u\"\\ufe0f\"  # dingbats\n",
    "                     u\"\\u3030\"\n",
    "                     \"]+\", re.UNICODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopword domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the set from nltk library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vaso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(text):\n",
    "    try:\n",
    "        lang, _ = langid.classify(text)\n",
    "        return lang == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in STOP_WORDS]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def cleanUp(field):\n",
    "    if field == None:\n",
    "        return \"\"\n",
    "    field = field.lower()\n",
    "    field = re.sub(CLEANR, ' ', field)\n",
    "    field = re.sub(r'[^\\w\\s]', ' ', field) # Remove punctuation\n",
    "    field = re.sub(r'\\d+', ' ', field) # Remove digits\n",
    "    field = re.sub(r'\\s+', ' ', field).strip() # Remove extra whitespaces\n",
    "    field = re.sub(r'\\b\\w\\b', ' ', field) # Remove single letters\n",
    "    field = re.sub(r'\\b\\w{2}\\b', ' ', field) #remove 2 letter words\n",
    "    field = re.sub(SYMBOLS_REGEX, '', field)\n",
    "    field = re.sub(SPECIAL_CHARACTERS_REGEX, '', field)\n",
    "    field = remove_stopwords(field)\n",
    "    return field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the preprocessed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_filtered = pd.read_csv(training_file_path, encoding='ISO-8859-1')\n",
    "df_test_filtered = pd.read_csv(test_file_path, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for attribute types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID       object\n",
       "text         object\n",
       "sentiment    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_filtered.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID       object\n",
       "text         object\n",
       "sentiment    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We index the text column. Tokenize the sentence, remove symbols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create index attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_indexed = df_training_filtered.copy()\n",
    "\n",
    "df_test_indexed = df_test_filtered.copy()\n",
    "\n",
    "\n",
    "for dataset in [df_training_indexed, df_test_indexed]:\n",
    "    dataset.loc[:,'index'] = dataset.loc[:,'text'].str.lower()\n",
    "    dataset.loc[:,'index'] = dataset.loc[:,'index'].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remote punctuation, digits, extra whitespaces, single letters, links, emoticons, symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in [df_training_indexed, df_test_indexed]:\n",
    "    for index, row in dataset.iterrows():\n",
    "        dataset.at[index, 'index'] = cleanUp(row['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>last session day http twitpic com ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>shanghai also really exciting precisely skyscr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>recession hit veronique branquinho quit compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>happy bday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>http twitpic com like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>0bb5b4d19c</td>\n",
       "      <td>Friday evening......what to do, what to do.  I...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>friday evening idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>e5f0e6ef4b</td>\n",
       "      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>tired sleep try</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>416863ce47</td>\n",
       "      <td>All alone in this old house again.  Thanks for...</td>\n",
       "      <td>positive</td>\n",
       "      <td>alone old house thanks net keeps alive kicking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373</th>\n",
       "      <td>6332da480c</td>\n",
       "      <td>I know what you mean. My little dog is sinkin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>know mean little dog sinking depression wants ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>df1baec676</td>\n",
       "      <td>_sutra what is your next youtube video gonna b...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sutra next youtube video gonna love videos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3375 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                               text sentiment  \\\n",
       "0     f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1     96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
       "2     eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3     01082688c6                                        happy bday!  positive   \n",
       "4     33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
       "...          ...                                                ...       ...   \n",
       "3370  0bb5b4d19c  Friday evening......what to do, what to do.  I...   neutral   \n",
       "3371  e5f0e6ef4b  its at 3 am, im very tired but i can`t sleep  ...  negative   \n",
       "3372  416863ce47  All alone in this old house again.  Thanks for...  positive   \n",
       "3373  6332da480c   I know what you mean. My little dog is sinkin...  negative   \n",
       "3374  df1baec676  _sutra what is your next youtube video gonna b...  positive   \n",
       "\n",
       "                                                  index  \n",
       "0                 last session day http twitpic com ezh  \n",
       "1     shanghai also really exciting precisely skyscr...  \n",
       "2     recession hit veronique branquinho quit compan...  \n",
       "3                                            happy bday  \n",
       "4                                 http twitpic com like  \n",
       "...                                                 ...  \n",
       "3370                                friday evening idea  \n",
       "3371                                    tired sleep try  \n",
       "3372  alone old house thanks net keeps alive kicking...  \n",
       "3373  know mean little dog sinking depression wants ...  \n",
       "3374         sutra next youtube video gonna love videos  \n",
       "\n",
       "[3375 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the indexed datasets to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_indexed.to_csv('../dataset/index/df_training_indexed.csv', index=False)\n",
    "\n",
    "df_test_indexed.to_csv('../dataset/index/df_test_indexed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
